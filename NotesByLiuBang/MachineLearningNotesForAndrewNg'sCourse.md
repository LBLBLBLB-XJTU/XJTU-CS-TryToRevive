# 机器学习笔记（吴恩达，机器学习）

## 机器学习基础

### 1机器学习

#### 1.1监督学习

监督学习是学习一种从X到Y的，或从输入到输出的映射算法。 其中的关键是由编码者提供学习算法示例以供学习。这个学习算法的示例，是指给算法一个正确答案，即给定输入X的正确的标签Y。算法通过学习输入X和正确的标签Y，这样一个数据对，达到只需要输入而不需要输出，并对输出进行合理地预测。

其中一种特殊的监督学习为回归,即试图从无数的可能的数字中预测一个数字.

另一种监督学习为分类,则在可能的几个值中进行预测,即预测类别

#### 1.2无监督学习

无监督学习是在无标签的数据中找到其中的信息

聚类是无监督学习的一种,将未标记的数据放入不同的集群中

异常检测是另一种无监督学习,用于检测异常的数据

降维也是一种无监督学习,它可以将大数据集在尽可能损失少的信息的情况下,压缩成一个小的数据集

### 2线性回归模型

#### 2.1线性回归模型

线性回归模型是一种监督学习,数据将被拟合为一条直线,输入一个数据,一个数字将被预测输出.

用于训练模型的数据集被称为训练集.机器学习中,表示输入的标准符号是小写x,称之为输入变量,或者是特征或输入特征,尝试预测的输出变量(或者称为目标变量)的标准符号为小写的y.一对(x,y)表示是一个训练示例,训练示例的总数则以小写m表示,在训练集中,($x^{(i)}$,$y^{(i)}$)表示第i个训练示例

将训练集提供给算法后,算法将提供一个功能,称为函数f.f将采用新的输入x进行估计或预测,输出出一个预测值$\hat{y}$,这时,函数f被称为模型,x是模型的输入,而预测$\hat{y}$则是模型的输出.注意,y是实际的目标值,而$\hat{y}$则是预测值,可能是真实的值也可能不是真实的值

对于f,考虑到线性回归模型,可以表示为$f_{w,b}(x)=wx+b$,或者简单的是$f(x)=wx+b$.至此,这就是单变量线性回归模型

#### 2.2代价函数

在上面的式子中,为w,b被称为模型的参数,b是截距,w是斜率.对于线性回归,即是找到w和b的过程.对于每个预测值和真实值,计算$(\hat y ^{(i)} - y^{(i)})^2$,并计算所有的预测值和对应的真实值然后求和,即:$\sum_{i=1}^m (\hat y^{(i)} - y^{(i)})^2$,m为训练用例的数量.这个式子会随着m的增大而增大,因此为了避免这一增大,我们采用平均平方误差,即$\frac{1}{m}\sum_{i=1}^m (\hat y^{(i)} - y^{(i)})^2$.此外,我们还会多除上一个2,以维持后续计算的整洁性:$\frac{1}{2m}\sum_{i=1}^m (\hat y^{(i)} - y^{(i)})^2$.即代价函数:$J_{(w,b)} = \frac{1}{2m}\sum_{i=1}^m (\hat y^{(i)} - y^{(i)})^2 $.

对于不同模型,可以采取不同的代价函数,而平均平方误差是线性回归中最常用的代价函数.

我们会希望代价尽量的小,即:$minimizeJ(w,b)$.

### 3梯度下降

#### 3.1梯度下降

梯度下降不仅仅可以用于最小化线性回归的代价函数,还适用于几乎所有的更一般函数$min_{w_1,\ldots,w_n,b}J(w_1,\ldots,w_n,b)$.

算法从随机的$w_i$和$b$的值开始,但是我们常常设置为0.我们不断的改变$w_i$和$b$的值,最终维持在最小值.

但是往往函数不会只有一个最小值,梯度下降能够解决这个问题.梯度下降能够为我们找到多个局部最小值.(好吧,这没有解决问题).梯下下降的思想是:每次向着下降最快的方向前进.如同一个人下山时,会360度张望,找到最陡的方向,然后前进,由此到达山谷.这时我们可以想到,我们会因为处于不同的山头而前往了不同的山谷,即可能有多个极小值.

#### 3.2梯度下降的实现

$w = w - \alpha \frac{\partial}{\partial w}J(w,b)$

* 式子中的$\alpha$称为学习率,通常是0到1之间的一个小整数,如0.01等.$\alpha$代表下降的步幅,如果大,意味着使用巨大的步幅下坡,小则说明以baby的小步幅下降.
* $\frac{d}{dw}J(w,b)$是式子的导数项.可以理解为下降的方向

$b = b - \alpha \frac{\partial}{\partial b}J(w,b)$

* $b$中字符的含义与$w$中的类似

我们将持续这个两个式子,直到$w,b$收敛.为了同时更新$w,b$我们需要同步的进行操作:

$temp\_w = w - \alpha \frac{\partial}{\partial w}J(w,b)$

$temp\_b = b - \alpha \frac{\partial}{\partial b}J(w,b)$

$w = temp\_w$

$b = temp\_b$

注意,应按顺序(或者说$temp$同时更新,$w,b$同时更新)更新,以维持同步.在机器学习的实现中,我们不太在乎是导数还是偏导数,所以此处的$d$和$\partial$意思是一样的.

每次朝着最陡的方向前进,在式子中的表现,即为导数项.又因为使用的是导数,所以可以认为是(极小范围内的)最陡的方向

#### 3.3学习率

如果学习率过低,每次的步幅较小,所以需要的次数过多.如果学习率过大,则步幅过大,可能直接略过了最低点,甚至发散.

学习率考虑的是下降的步伐,因此理想情况下学习率的多少不妨碍达到局部最小.

#### 3.4线性回归中的梯度下降

针对上面$w,b$更新的式子,式子中的导数项如下推导:

$\frac{\partial}{\partial w}J(w,b) = \frac{\partial}{\partial w} \frac{1}{2m} \sum_{i = 1}^m(f_{w,b}(x^{(i)}) - y^{(i)})^2 = \frac{\partial}{\partial w} \frac{1}{2m} \sum_{i = 1}^m(wx^{(i)} + b - y^{(i)})^2 =  \frac{1}{2m} \sum_{i = 1}^m(wx^{(i)} + b - y^{(i)})2x^{(i)} = \frac{1}{m} \sum_{i = 1}^m(wx^{(i)} + b - y^{(i)})x^{(i)} = \frac{1}{m} \sum_{i = 1}^m(f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)}$.

$\frac{\partial}{\partial b}J(w,b) = \frac{\partial}{\partial b} \frac{1}{2m} \sum_{i = 1}^m(f_{w,b}(x^{(i)}) - y^{(i)})^2 = \frac{\partial}{\partial b} \frac{1}{2m} \sum_{i = 1}^m(wx^{(i)} + b - y^{(i)})^2 =  \frac{1}{2m} \sum_{i = 1}^m(wx^{(i)} + b - y^{(i)})2 = \frac{1}{m} \sum_{i = 1}^m(wx^{(i)} + b - y^{(i)}) = \frac{1}{m} \sum_{i = 1}^m (f_{w,b}(x^{(i)}) - y^{(i)})$.

将这两个式子塞入梯度下降的式子中即可.对于线性回归,只有一个极小值,所以结果是全局最小值.

实际上这个是批量梯度下降,因为我们在梯度下降时考虑了所有的数据.

### 4多类特征

在上面的情况中,我们的输入x都是一维的.进一步的,我们将维数扩展到多维,用$x_j$表示,$j$最大将是$n$,为总共的维数.而上标则表示第几个用例的特征,为一个行向量,如$x^{(2)} = [1,0,1,4]$.那么在这里有$x_j^{(i)}$表示第$i$个用例的第$j$个特征,如$x_2^{(2)} = 0$.

那么模型改为:

$f_{w,b}(x) = w_1x_1 + w_2x_2 + w_3x_3 + \ldots + w_nx_n + b$

用$\vec w = [w_1, w_2, \ldots ,w_n]$和$\vec x = [x_1, x_2,\ldots,x_n]$来替换式子,有:

$f_{(\vec w,b)}(\vec x) = \vec w \cdot \vec x +b$

这样的模型称为多元线性回归.

#### 4.1向量化

在线性代数中,向量中的内容从1开始记.而在python中,向量中的内容从0开始记.

对于python代码,可以像下面来表示$\vec w,b,\vec x$(使用Numpy库):

```python
w = np.array([1.0,2.5,-3.3])
b = 4
x = np.array([10,20,30])
```

那么对应的模型的公式计算的代码为:

```python
f = w[0] * x[0] +
    w[1] * x[1] +
    w[2] * x[2] + b
```

更简单的,使用for循环:

```python
f = 0
for j in range(0,n)
    f = f + w[j] * x[j]
f = f + b
```

最终的使用向量来简化以及利用NumPy库的并行能力来加速计算:

```python
f = np.dot(w,x) + b
```

在前两段代码中,计算线性的执行:每次对一对$w,x$求和.而向量化的计算中,计算机硬件得到所有的$w$和$x$,利用硬件能力并行的在同一时间对每对$w,x$求和,从而加速速度.

同样的,在进行梯度下降时,导数项也可以用一个向量表示,使得梯度下降时对$w,b$的更新也可以加速

#### 4.2多元线性回归的梯度下降

对于模型:

$f_{(\vec w,b)}(\vec x) = \vec w \cdot \vec x +b$,

则代价函数为:

$J(\vec w,b)$,

则对应的梯度下降公式为:

$w_j = w_j - \alpha \frac{\partial}{\partial w_j} J(\vec w, b) = w_j - \alpha \frac{1}{m} \sum_{i = 1}^m (f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})x_j^{(i)} $和

$b = b - \alpha \frac{\partial}{\partial b} J(\vec w, b) = b - \alpha \frac{1}{m}  \sum_{i = 1}^m (f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})$.

另外的,有一种只适用于线性回归、不需要对$w,b$进行迭代的方法:正态方程法.

### 5一些技术细节

#### 5.1特征放缩

特征放缩是一种对梯度下降进行加强的技术.

考虑一些训练用例中的值,一些值会特别大,而另一些会特别小.根据经验,我们会对大的值选择的一个小的参数,对小的值选择一个大的参数.反映到图上,有散点图会偏向于一个轴以及等高线图中图特别窄.这将直接的导致梯度下降处于一个不利的状态.

在这种情况下,我们希望使值处在一个可比的范围内.

#### 5.2特征放缩的实现

第一种方法是利用比例将值都放在0到1之间的值.

第二种方法是平均归一,将值放在-1到1之间.首先会求平均值,然后将每个值都减去平均值,然后再除以区间的宽度.

最后一种方法是Z归一化,求出平均数和标准差,每个值减去平均数,然后除以标准差

#### 5.3梯度下降的收敛

可以画一个横轴为迭代次数,纵轴为J的图,理想情况下,随着迭代次数的增加,J应该下降,如果J出现波动,则说明学习率可能取得过大.此外,图中曲线的收敛也代表着在迭代了多少次后接近收敛以及对应的J.

另一种是自动收敛测试:设置一个极小的值$\epsilon$,如果每次迭代的差值小于这个值,则可以认为已经收敛,但是这个阈值往往非常难以找到

#### 5.4学习率的选择

通过画上一节中所说的图,我们希望随着迭代次数的增加,J逐步下降,如果出现了上升或者波动,则说明可能学习率过大.在调试时,往往从一个较小的值增大到一个较大的值.

#### 5.5特征工程

需要良好的特征,才能使得模型的运作良好.

直接采集到的特征有时不能更好的反应特征,因此,我们可以用这些特征去组合出一个新的特征,将这个新的特征塞入模型,这就是特征工程

#### 5.6多项式回归

有特征工程,我们引入了多项式回归,由此我们可以对非线性的函数进行拟合

多项式中,不仅有自变量的一次项,还有自变量的多次项,为此特征放缩是非常重要的

### 6分类

线性回归并不是分类的好方法,我们需要一些新的方法来进行分类

首先对于简单的是或不是的分类,这一类被称为二进制分类,通常用0,false,阴性,负来表示一类,用1,true,阳性,正来表示另一类.这时可以明显的看出线性回归是效果不好的.

#### 6.1逻辑回归

逻辑回归将输出的值限制为0或者1.虽然名字是回归,但实际是分类算法.

逻辑函数往往表示为一条去拟合训练用例的曲线,曲线对应的值表示接近0或者1的程度.

sigmoid函数是最著名的逻辑函数,他的输入是负无穷到正无穷,输出在0到1之间.sigmoid函数:$g(z) = \frac{1}{1+e^{-z}}$.当输入正无穷,输出接近1,而输负无穷,输出接近0.

构建时,我们令$z = \vec w \cdot \vec x + b$,然后塞入公式,即有$f_{\vec w,b}(\vec x) = \frac{1}{1+e^{-(\vec w \cdot \vec x +b)}}$.这就是逻辑回归模型.输出可以认为是预测为1的概率,即可以理解为$f_{\vec w, b}(\vec x) = P(y = 1 | \vec x; \vec w,b)$.

#### 6.2决策边界

在上一节我们看到最后的结果实际上时一种对结果为1或者为0的概率的表示,往往我们会选择当结果大于0.5时,认为为1,反之为0.由此,使得结果为0.5的x的值,就是决策边界.

针对sigmoid函数,z大于0时,结果大于0.5,即$\vec w + \cdot \vec x + b >0$,结果认为为1,反之为0.当z等于0时,自变量的条件称为决策边界.这个边界与具体的模型有关,可以是任意不同的形状

### 7逻辑回归的代价函数

设定模型中有$i=m$个训练用例,$j=n$个特征,目标值只有$y = 1or0$.使用逻辑回归方法时,如果仍然使用平均平方误差,会导致陷入很多的局部最小中(因为此时的图是一个波动的凹函数).由此作出改变.

首先对于单个用例,Loss函数为:

$L(f_{\vec w,b}(\vec x^{(i)}),y^{(i)}) =    \begin{cases}     -\log \left(f_{\overrightarrow{\mathbf{w}}, b}\left(\overrightarrow{\mathbf{x}}^{(i)}\right)\right) & \text{if } y^{(i)}=1 \\     -\log \left(1 - f_{\overrightarrow{\mathbf{w}}, b}\left(\overrightarrow{\mathbf{x}}^{(i)}\right)\right) & \text{if } y^{(i)}=0   \end{cases}$.考虑这两个log函数,当f的结果分别接近1和0时,两个log内的也接近1,使得整个L接近0;如果不接近1和0,会导致log内的部分向纵轴移动,使得函数的值变得巨大,即L很大.这时符合我们要求的.所以代价函数为:

$J(\vec w,b) = \frac{1}{m} \sum_{i=1}^{m} \begin{cases}     -\log \left(f_{\overrightarrow{\mathbf{w}}, b}\left(\overrightarrow{\mathbf{x}}^{(i)}\right)\right) & \text{if } y^{(i)}=1 \\     -\log \left(1 - f_{\overrightarrow{\mathbf{w}}, b}\left(\overrightarrow{\mathbf{x}}^{(i)}\right)\right) & \text{if } y^{(i)}=0 \end{cases}$.

考虑到y只能取1或者0,可以有:

$L(f_{\vec w,b}(\vec x^{(i)}),y^{(i)}) = -y^{(i)}\log (f_{\vec w,b}(\vec x^{(i)})) - (1-y^{(i)})\log (1-f_{\vec w,b}(\vec x^{(i)}))$.那么进一步的有:

$J(\vec w,b) = -\frac{1}{m} \sum_{i=1}^{m}[ y^{(i)}\log (f_{\vec w,b}(\vec x^{(i)})) +(1-y^{(i)})\log (1-f_{\vec w,b}(\vec x^{(i)}))]$.这个代价函数是凹函数,可以顺利的进行梯度下降

### 8逻辑回归的梯度下降实现

考虑新的代价函数,则导数项分别为:

$\frac {\partial}{\partial w_j}J(\vec w,b) = \frac{1}{m}\sum_{i=1}^{m}(f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})x_j^{(i)}$和

$\frac {\partial}{\partial b}J(\vec w,b) = \frac{1}{m}\sum_{i=1}^{m}(f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})$.然后只需同步的进行梯度下降即可.但是注意此时的$f$已经变成了$f_{\vec w,b}(\vec x) = \frac{1}{1+e^{-(\vec w \cdot \vec x +b)}}$.

在此之后,通过观察学习曲线,向量化和特征放缩来加速梯度下降

### 9过拟合

模型过于拟合训练集,导致失去了通用性,则可以称为过拟合.代价过大,我们称为高偏差,而过拟合,则称为高反差,我们希望偏差和方差都不要高.

#### 9.1过拟合的解决

解决的第一个方法就是更多的数据,更大的训练集.但是有时我们无法获取更多的数据

其次,需要选择特征,并不是所有的特征对于模型都是有益的.这个的优点是可以直观的选择最有关的信息,而缺点这时可能遗漏那些没被选择的特征中信息.

第三种方法是正则化,把对应的某个参数变小.可以把这个功能视为更加委婉的进行特征选择.这个方法可以减小某些特征的影响,但是仍然保持特征的存在.一般只对$w$进行操作,而不对$b$进行操作

#### 9.2正则化代价函数

如果一个特征对应的参数我们认为不重要,即参数非常小(接近0),那么在代价函数中,我们就修改代价函数,在原本的代价函数中添加上特征乘上一个特别大的参数.这样即可认为是对这个特征的惩罚.因为如果这个特征稍微的变化,代价函数就会剧烈的变化,所以,这个特征只能特别小(接近零),可以视为被排除了出去.

而实际上,在训练开始时,我们不知道哪一个特征是不重要的,所以我们选择对每个特征都进行惩罚,那么修改后的代价函数是:

$j(\vec w,b) = \frac{1}{2m} \sum_{i = 1}^m(f_{w,b}(x^{(i)}) - y^{(i)})^2 + \frac{\lambda}{2m}\sum_{j = 1}^{n}w_j^2$.其中n是特征的个数,$\lambda$被称为正则化参数,大于零.这时的代价函数分为两部分,第一部分的平均平方误差用于拟合数据,而第二部分的正则化项则用于保持每个特征的参数都比较小(以防止过拟合).而$\lambda$则用于在两个部分中权衡.当$\lambda$为0,代价函数取决于平均平方误差,无法应对过拟合;若非常大,则使得每个特征的参数都非常小,则模型只取决于$b$,失去了拟合的功能.

#### 9.3正则化线性回归

对于上面提到的正则化的代价函数,那么新的导数项将是:

$\frac {\partial}{\partial w_j}J(\vec w,b) = \frac{1}{m}\sum_{i=1}^{m}(f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})x_j^{(i)} + \frac{\lambda}{m}w_j$和

$\frac {\partial}{\partial b}J(\vec w,b) = \frac{1}{m}\sum_{i=1}^{m}(f_{\vec w,b}(\vec x^{(i)}) - y^{(i)})$.注意此时只有$w$的变化了(因为没有对$b$操作).利用这两个公式即可进行梯度下降.

将$w$梯度下降公式如下改写:$w_j = w_j - \alpha \frac{\lambda}{m}w_j- \alpha \frac{1}{m} \sum_{i = 1}^m(f_{w,b}(x^{(i)}) -  y^{(i)})x^{(i)} = w_j(1-\alpha \frac{\lambda}{m}) - \alpha \frac{1}{m} \sum_{i = 1}^m(f_{w,b}(x^{(i)}) -  y^{(i)})x^{(i)}$.可以看出,后一项是在此的梯度下降的更新,而第一项,旧的参数值,将会被乘上一个系数.$\lambda $越大,旧的参数会越小,实现了正则化所希望的将参数变小的意愿.

#### 9.4正则化逻辑回归

正则化后,逻辑回归的代价函数是:

$J(\vec w,b) = -\frac{1}{m} \sum_{i=1}^{m}[ y^{(i)}\log (f_{\vec w,b}(\vec x^{(i)})) +(1-y^{(i)})\log (1-f_{\vec w,b}(\vec x^{(i)}))] +\frac{\lambda}{2m}\sum_{j = 1}^{n}w_j^2$.同样的,只需要在$w$导数项的后面加上附加项$\frac{\lambda}{m}w_j$.即可.

## 高级学习算法

### 1深度学习

深度学习由大脑的工作原理中受到启发.大脑中的神经元互相连接,当某个神经元的电势超过阈值,则会向下一个神经元发送电荷.由此重复实现神经的连接.不过现在的神经网络已经不在考虑生物原理了.

对于每个神经元,我们输入一些值,神经元里的函数会输出一个值.我们使用$a$来表示输出,意为activation激活.接受输入的一层神经元称为输入层,输入了特征向量$\vec x$.最后输出的一层神经元称为输出层,而二者之间的层称为隐藏层.

### 2神经网络

#### 2.1每一层的构建

对于某一层中的某个神经元,都是一个小的逻辑回归单元.以其中的第一个单元为例子,这个单元同样有两个参数$\vec w_1,b_1$,这个神经元会输出$a_1 = g(\vec w_1 \cdot \vec x +b_1)$.同一层的单元也是这样.它们的输出$\vec a = [a_1, a_2,\cdots]$就是激活向量,传递给下一层,作为下一层的输入向量.我们用方括号上标来表示层数,上面的例子就是:$a_1^{[1]} = g(\vec w_2^{[1]} \cdot \vec x + b_1^{[1]})$和$\vec a^{[1]} = [a_1^{[1]},a_2^{[1]},\cdots]$,表示第一层的第一个神经元的相关信息,那么下一层的第一个神经元就有:$a_1^{[2]} = g(\vec w_1^{[2]} \cdot \vec a^{[1]} + b_1^{[2]})$.

#### 2.2更复杂的神经网络

对于第$l$层的第$j$个神经元(这里假定输入$\vec x = \vec a^{[0]}$),有:$a_j^{[l]}= g(\vec w_j^{[l]} \cdot \vec a^{[l-1]} + b_j^{[l]})$.其中函数$g$是神经元的激活函数(不仅仅是sigmoid函数).

### 3代码构建

#### 3.1代码中的推理

TensorFlow是神经网络构建使用的常用框架.对于一个简单的网络的一部分,可以有:

```
x = np.array([200, 17])
layer_1 = Dense(units=3, activation='sigmoid')
a1 = layer_1(x)
```

这段代码首先给出了一个具有两个特征的向量x,然后设置了第一层,这层使用了3个神经元和sigmoid函数作为激活函数.然后放入x得到第一层的激活向量.这个向量将由三个值,对应三个神经元.

#### 3.2TensorFlow与NumPy的数据格式

上面是一个向量进入网络,只代表了1个训练用例.对于一组训练用例,可以用矩阵表示.如:

```python
x = np.array([[1, 2, 3]
              [4, 5, 6]])
```

这样表示了一个2乘3的矩阵:$\begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}$.在上一节的代码中执行了计算生a_1后,实际上a_1是这样的一个数据结构:

```python
tf.Tensor([[0.2 0.7 0.3]], shape=(1,3), dtype=float32)
```

Tensor是一种特殊的数据结构用于存储矩阵,shape表示矩阵的形状,dtype是格式.如果想要转换为矩阵格式,则可以用`a1.numpy()`即可.

#### 3.3构建神经网络

下面是一个简单的对模型的训练:

```python
layer_1 = Dense(units=3, activation="sigmoid")
layer_2 = Dense(units=1, activation="sigmoid")
model = Sequential([layer_1, layer_2])

x = np.array([[200, 17]
              [120, 5]
              [425, 20]
              [212, 18])
y = np.array([1,0,0,1])

model.complie(...)
model.fit(x,y)
```

训练后如过有一组x_new来给你需要预测,只需`model.predict(x_new)`即可.

一般进行实践中,我们不会单独用layer_1,layer_2来表示,而是直接塞入Sequential中.

### 4前向传播

#### 4.1一个层内的前向传播

对于一个假定的简单的神经网络中的第一层的第一个神经元有:

```python
w1_1 = np.array([1, 2])
b1_1 = np.array([-1])
z1_1 = np.dot(w1_1,x) + b
a1_1 = sigmoid(z1_1)
```

第二个神经元有:

```python
w1_2 = np.array([-3, 4])
b1_2 = np.array([1])
z1_2 = np.dot(w1_2,x) + b
a1_2 = sigmoid(z1_2)
```

相应的其他神经元也是如此,则有`a1 = np.array([a1-1, a1_2, a1_3,...])`.

#### 4.2前向传播的一般实现

首先我们实现Dense函数:

```python
def dense(a_in, W, b, g):
    units = W.shape[1]
    a_out = np.zeros(units)
    for j in range(units):
        w = W[:, j]
        z = np.dot(w,a_in) + b[j]
        a_out[j] = g(z)
    return a_out 
```

这里的输入a_in,b是一个向量,W是矩阵.首先根据W矩阵的shape成员的[1]来获取有这一层多少个单元,然后初始化输出.在for循环中遍历,`w = W[:, j]`这句话是抽出W中的第j列.之后获取每一个输出,然后输出.

接着实现一个简单的sequential函数:

```python
def sequential(x):
    a1 = dense(x, W1, b1)
    a2 = dense(a1, W2, b2)
    a3 = dense(a2, W3, b3)
    a4 = dense(a3, W4, b4)
    f_x = a4
    return f_x
```

### 5神经网络的高效实现

向量化,矩阵乘法为神经网络的高速实现创造了基础,而并行计算硬件这加速了神经网络的计算.

在上一节中,我们的dense函数使用了for循环来循环的计算,向量化可以加速这一过程:

```python
X = np.array([[200, 17]])
W = np.array([[1, -3, 5]
              [-2, 4, -6])
B = np.array([[-1, 1, 2]])

def dense(A_in, W, B):
    Z = np.matmul(A_in, W) + B
    A_out = g(Z)
    return A_out
```

注意,X,W,B都是大写,表明都是矩阵,matmul方法是矩阵乘法.当然,结果也是一个矩阵如`[[1, 0, 1]]`.

#### 5.1矩阵乘法

对于矩阵乘法,我们首先考虑向量之间的点乘.例如$ z = \begin{bmatrix} 1 \\ 2 \end{bmatrix} \cdot \begin{bmatrix} 3 \\ 4 \end{bmatrix} = \begin{bmatrix} 1 \\ 2 \end{bmatrix} \begin{bmatrix} 3 & 4 \end{bmatrix} = 1 \times 3 + 2 \times 4 = 11$.那么进一步的有:

$z = \vec a \cdot \vec w = \vec a^T \vec w$

接下来考虑向量和矩阵的乘法.例如$Z = \begin{bmatrix} 1 \\ 2 \end{bmatrix} \cdot \begin{bmatrix} 3 & 4 \\ 5 & 6 \end{bmatrix} = \begin{bmatrix} 1 & 2 \end{bmatrix} \begin{bmatrix} 3 & 4 \\ 5 & 6 \end{bmatrix} = \begin{bmatrix} 1 \times 3 + 2 \times 4 & 1\times 5 + 2 \times6 \end{bmatrix} = \begin{bmatrix} 11 & 17 \end{bmatrix}$.那么进一步的有:

$Z = \vec a \cdot W = \vec a^TW$

最后,考虑矩阵乘法.例如:$Z = \begin{bmatrix} 1 & -1 \\ 2 & -2 \end{bmatrix} \cdot \begin{bmatrix} 3 & 5 \\ 4 & 6 \end{bmatrix} = \begin{bmatrix} 1 & 2 \\ -1 & -2 \end{bmatrix} \begin{bmatrix} 3 & 5 \\ 4 & 6 \end{bmatrix}  = \begin{bmatrix} 1 \times3+2\times 4 & 1 \times 5+2\times 6 \\  -1 \times 3-2\times 4& -1 \times 5-2\times 6 \end{bmatrix} = \begin{bmatrix} 11 & 17 \\ -11 & -17 \end{bmatrix}$.首先我们考虑什么是转置,转置实际是让原来矩阵的每一列,转置后称为每一行.然后我们看乘法,乘法实际上是第一个矩阵的行和第二个矩阵的列进行向量乘法.那么进一步的有:

$Z = A \cdot W = A^TW = \begin{bmatrix} \vec a_1^T\vec w_1 &  \vec a_1^T\vec w_2 & \cdots &  \vec a_1^T\vec w_n \\ \vec a_2^T\vec w_1 &  \vec a_2^T\vec w_2 & \cdots &  \vec a_2^T\vec w_n \\ \cdots & \cdots & \cdots & \cdots \\ \vec a_n^T\vec w_1 &  \vec a_n^T\vec w_2 & \cdots &  \vec a_n^T\vec w_n \end{bmatrix}$

可见,第一个矩阵的行数(转置后的列数)必须与第二个矩阵的行数相同,结果矩阵的行数是第一个矩阵的列数(转置后的行数),列数是第二个矩阵的列数

#### 5.2矩阵乘法的代码

实现的代码如下:

```python
A = np.array([...])
AT = np.array([...])
W = np.array([...])
B = np.array([...])

def dense(AT, W, B, g):
    Z = np.matmul(AT, W) + b
    A_out = g(Z)
    return A_out
```

### 6TensorFlow实现网络

#### 6.1用TensorFlow实现网络

下面是一个简单的示例:

```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.losses import BinaryCrossentropy

model = Sequential([
    Dense(units=25, activation='sigmoid')
    Dense(units=15, activation='sigmoid')
    Dense(units=1, activation='sigmoid')
])
model.compile(loss=BinaryCrossentropy())
model.fit(X, Y, epochs=100)
```

代码先引入需要的库,然后设定为3层的模型,分别有25,15,1个神经元,激活函数全都使用sigmoid.接着进行编译,指定loss函数为BinayCrosentropy.然后利用X和Y进行训练,epochs参数指定了梯度下降的次数(实际上是BP的迭代次数).

#### 6.2训练中的细节

训练一个模型的步骤如下:

* 确定输出函数
* 确定loss函数和代价函数
* 最小化代价函数

在神经网络中,输出函数由Sequential函数确定,loss函数由compile函数中的参数确定,进而代价函数也确定了,最后的fit函数对模型进行训练最小化代价函数.

### 7激活函数

在实际上,激活函数不仅有sigmoid一种,例如ReLu函数$g= max(0,z)$,或是线性激活函数$g= z$,这几个就是最常用的激活函数.当然除此之外还有其他激活函数.

#### 7.1选择激活函数

对于输出层,我们基本上是根据标签来选择激活函数的,例如二进制分类问题,结果要么0要么1,就选择sigmoid.如果预测股票的变化,输出可正可负,那么就可以训着线性激活函数.如果预测房价,结果只会是正值,那么可以选择Relu作为激活函数.

对于隐藏层和输入层,最常用的是ReLu,相对于sigmoid,ReLu计算速度快,而且只有纵轴左侧一个平坦处,这将使得梯度下降变得更快.

#### 7.2为什么使用激活函数

1. **引入非线性**:如果没有激活函数,神经网络的每一层都是线性变换（即,线性组合的结果仍然是线性的,最终整个网络的输出仍然是输入的线性函数.这样意味着神经网络在没有激活函数的情况下,无法模拟复杂的非线性关系.激活函数引入非线性特性,使得网络能够处理复杂的数据并学习复杂的模式.
2. **使得模型更具表达能力**: 通过在网络中引入非线性,神经网络能够捕捉到更多的数据特征和细节,这增强了模型的表达能力,使它能够解决更多样化和复杂的问题.
3. **神经网络的深度学习能力**: 深度神经网络依赖多个隐藏层来逐步抽象和提取数据的特征,每一层的非线性激活允许网络学习和捕捉不同层次的特征.没有激活函数的网络只能解决线性可分离的问题.
4. **激活函数的不同特性使得网络更灵活**: 常用的激活函数如ReLU（Rectified Linear Unit）、Sigmoid和Tanh等各有特点,在不同的情况下可以让网络表现得更好.例如，ReLU激活函数在实践中较为常用,因为它计算简单,而且在深层网络中有助于缓解梯度消失问题.

### 8多类

多类指多分类类问题,输出的标签有多个值.我们会使用softmax回归来实现.

#### 8.1softmax

softmax是逻辑回归的推广,是一种针对多类分类上下文的二进制分类算法.逻辑回归算法可以认为是两个输出的概率分布,那么扩展到多类,就是若干个输出的概率的分布.

那么有:对于N个可能的输出中的j,有$z_j = \vec w_j \cdot \vec x + b_j,a_j = \frac{e^{z_j}}{\sum_{k=1}^{N}e^{z_k}}=P(y=j|\vec x)$.值得注意的是,softmax的输出与所有的$z$有关

对应的,loss函数为:$\begin{cases} -\log a_1 & \text {if } y=1 \\ -\log a_2 & \text{if }y=2 \\ & \vdots \\ -\log  a_n & \text{if } y=n \end{cases}$.

#### 8.2神经网络中的softmax

对于多类问题,我们考察输出对应每个可能的输出值的情况.所以输出层将有N个单元(对应可能输出值的个数),$a_j$对应第$j$个输出神经元的输出.

一个简单的示例如下:

```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model = Sequential([
    Dense(units=25, activation='sigmoid')
    Dense(units=15, activation='sigmoid')
    Dense(units=10, activation='softmax')
])
model.compile(loss=SparseCategoricalCrossentropy())
model.fit(X, Y, epochs=100)
```

这个代码可以运行,但是不是一个好的例子,不要使用这样的代码.

#### 8.3softmax的改进实现

考虑每个$a_j$的输出公式,公式中有一个巨大的分数,考虑到分数,我们要了解到由于浮点数的原因,我们不能进行一些计算,因为会存在误差.为此我们需要改进.

最初我们计算loss时把输出带入了进去计算,但是我们可以直接将输入的$z$带入进去,而不再使用输出这一个中间值.具体到代码上时:

```python
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.losses import SparseCategoricalCrossentropy

model = Sequential([
    Dense(units=25, activation='sigmoid')
    Dense(units=15, activation='sigmoid')
    Dense(units=10, activation='linear')
])
model.compile(loss=SparseCategoricalCrossentropy(from_logits=True))
model.fit(X, Y, epochs=100)
logits = Model(X)
f_x = tf.nn.softmax(logits)
```

代码中我们输出层的激活函数改为了线性激活函数,logits是z的向量,在输出时再对z使用softmax得到结果.如果是二分类,我们也要做类似的操作.

#### 8.4多个输出的分类

还有一种叫做多标签分类的问题.例如,给一张图片,看图中是否有汽车,是否有公交车,是否有行人.输出是一个向量,向量中三个数字对应问题的答案(注意这与多类问题的不同).一种麻烦的方法是训练三个网络来考察三个问题.但是更好的是我们可以使用一个网络来实现,在输出层中对每个输出神经元使用sigmoid.

### 9高级优化方法

我们提出一个比梯度下降更好的优化方式Adam(Adaptive Moment estimation,自适应矩估计).Adam会自动调节学习率来优化学习过程,而且是对每个参数,可以有不同调节过程.Adam的思想是:如果梯度优化向着一个大致方向,那么就可以提高学习率,如果方向大幅改变,就要降低学习率.在代码中:

```python
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))
```

注意仍然需要给出一个初始学习率.

此外,之前我们一直使用的是Dense层,每个神经元与上一层的所有输出有关.但是同样有一些其他的层存在.例如卷积层,每个神经元将收到有限区域的像素而不是整个图像.它的优点是计算更快,需要更少的数据.

### 10构建学习系统

#### 10.1模型评估

为了判断模型的好坏,我们可以从训练集中抽出一部分,作为测试集,在测试集上对模型进行测试.当然,代价函数就分为了训练时的代价和测试时的代价(注意这时计算代价不要添加正则化项).对于分类问题,那么代价可以简单的以错误预测除以总测试数来计算.

#### 10.2模型选择与训练交叉验证测试集

我们可以对提出的每一种模型都计算测试集上的代价,选择最低的一个模型.但是仅在测试集上进行决定仍然可能存在不足,是一个过于乐观的估计.进一步的我们可以将数据集分为多个结合.例如分为三个,一个训练集,一个交叉验证集,一个测试集.这时就有了三个J(同样计算时不计正则化项),可以根据这三个J来选择(一般根据交叉验证的误差来选,用测试的误差来报告误差).

### 11模型诊断

高偏差是拟合的不好,高方差是拟合的过好.我们将主要利用$J_{cv},J_{train}$,根据这两个方向来对模型进行调整,尤其是基于交叉验证集上的J.

#### 11.1模型与偏差和方差:模型多项式次数的选择

模型的好坏会有一些显示:

对于偏差大的模型,可能在训练集上就做的不好:$J_{train} \text{is high},J_{cv} \text{is high}$.

对于方差大的模型,在训练集上效果好但是在CV集和测试集上不好:$J_{train} \text{is low},J_{cv}\text{is high}$.

当然,一个相当坏的模型可能二者都高:$J_{train}\text{is high},J_{cv}\text{is high, and } J_{cv} \gg J_{train}$.

对于比较好的模型,在训练集和CV集上效果都很好:$J_{train}\text{is low},J_{cv}\text{is low}$.

我们可以看到,对于模型影响相当大的部分是模型多项式的次数,明显,随着多项式次数的增加,$J_{train}$会逐步的下降,而$J_{cv}$则会先下降又增加.

#### 11.2正则化与偏差和方差:正则化参数的选择

在之前的章节中,我们使用了$\lambda$,这个正则化参数,来优化代价函数以及模型.当$\lambda$大,算法被高度激励,每个参数将都倾向于非常小,模型接近于一个常数项,显然,具有高偏差.反之,当$\lambda$为0,算法不存在正则化,模型将高度的拟合,显然则有高方差.所以,选择一个合适的$\lambda$十分重要.为此,我们选择不同的$\lambda$,然后计算对应的$J_{cv}$.$J_{cv}$最小时,对应的$\lambda$是最佳的.然后我使用$J_{test}$作为报告上写的代价

考虑直观的图像,当$\lambda$增大,参数的作用倾向于变小,说明$J_{train}$将逐渐变大;而对于$J_{cv}$,$\lambda$过小时会过拟合,过大时会不拟合,所以呈现出先下降后增加的曲线.

#### 11.3建立表现基准

在上面的章节中,我们提到高偏差和高方差,那么这个高是多高,我们将使用表现基准来确定.

表现基准可以直观的理解为我们希望模型到达的程度,一种常用的方式确定以人类的水平为基线.另一种方式则是以其他的算法的水平.

如果训练集代价与基准展示的代价相差大,说明高偏差;如果CV集与训练集的差异大,则说明高方差.

#### 11.4学习曲线

学习曲线的横轴是训练集的大小,纵轴是代价函数的值($J_{train}orJ_{cv}$).随着训练集的增大,$J_{cv}$将会逐渐减小,因为参数会被优化.而$J_{train}$则会逐渐增大,因为模型试图拟合更多的点位,但是模型能力限制了自身.当然,前者总会大于后者.

对于高偏差的算法,模型自身是最大的限制,图像上两条线在上面的基础上会逐渐趋平,因为参数的优化将影响不再那么大了.表现基准在右侧,将在两条线的下面的远处.这时意味着更大的数据集也无济于补

对于高方差的算法,两条线之间的距离则会很大,基准线处于不一定的位置.但是此时增大训练集,则可以减小$J_{cv}$,实现优化.

#### 11.5模型的优化方法:

对于高偏差模型:

* 使用更多的特征
* 增加多项式特征
* 降低正则化参数

对于高方差模型:

* 更多的训练用例
* 使用更少的特征
* 升高正则化参数

#### 11.6神经网络与偏差和方差

我们可以证明,在小的数据集上,神经网络是一个低偏差的模型.

一般我们有这样的过程:开始时考察是否在训练集上做得好,不好的的话就增大神经网络,再次测试,若好,就测试CV集,若CV集上不好,就增加数据,回到训练集上继续测试,若好,则完成训练.

而且,事实证明,更大的神经网络并不会增加方差.需要正则化时,代码的改变只需要在层函数中添加一个参数:

```python
layer = Dense(units=25, activation='relu', kernel_regularizer=L2(0.01))
```

### 12机器学习相关技术

#### 12.1迭代发展

进行机器学习无非是下面的过程:

* 初始化结构
* 训练
* 诊断模型
* 根据诊断迭代模型
* 返回第二步再次训练

#### 12.2误差分析

对于CV集中错误的用例,我们将这些用例取出,然后观察,分类,总结出这些错误用例的特征,然后根据这些特征对模型进行改进.

#### 12.3添加数据

毫无疑问,我们希望获取更多的数据.但是往往这时很难的.那么有以下几种方法:

* 数据增强:修改原有数据生成新的数据.例如图像中的图像旋转、改变图像大小,改变图像对比度,镜像,增加网格随机弯曲等,音频中的增加噪声等
* 数据合成:创造全新的数据.例如向文本中添加随机字符等

由此,引出两种机器学习的方法:一种是以模型为中心,关注模型与算法;另一种是以数据为中心,关心数据

#### 12.4迁移学习

如果问题因为数据很少等原因难以训练,我们可以选择一个其他问题的模型,迁移过阿里,保持原有参数,然后修改输出层和输入层即可.然后在训练时,使用本问题的数据对迁移过来的模型进行修改即可.

在这里的训练时,有两种方法:只训练输出层参数,或者训练所有的参数.这取决于你的训练集的大小

#### 12.5机器学习项目的完整周期

首先,要求划分项目,确定要做什么

接着要确定并收集数据

接着进行模型训练,包括训练,误差分析,迭代,可能还需继续收集数据

最后部署生产环境,并保持维护

### 13倾斜数据集的处理

如果一个数据集中部分标签过多而例外部分标签过少,这样的倾斜数据集使用通常的误差度量,往往没有那么有效.

#### 13.1倾斜数据集的误差指标

为此我们定义精确率和召回率.以二分类为例,对于CV集中的数据:实际为1预测为1,称为真阳(True positive),实际为1预测为0,称为假阴(False negative),实际为0预测为1,称为假阳(False positive),实际为0预测为0,称为真阴(True negative).那么精确度为$\frac{真阳}{真阳+假阳}$,召回率为$\frac{真阳}{真阳+假阴}$.

#### 13.2精确率和召回率的权衡

在逻辑回归中,我们使用0.5作为阈值,决定结果为1还是0.但是考虑到倾斜数据集,我们应该改变这个阈值.

提高阈值,意味着只有非常有信心的时候才输出1,则提高了精确率,但降低了召回率

降低阈值,意味着我们不想错过,能输出1就输出1,则降低了精确率,但提高了召回率

这时,我们是手动调整阈值,根据对精确率和召回率的感觉来调节.

如果想自动的调节,则有一个结合了精确率和召回率的F1分数(调和平均值)$F_1 = \frac{1}{\frac{1}{2} (\frac{1}{P} + \frac{1}{R})}$.这个分数的结果将倾向于比较小的那一个.

### 14决策树

决策树尤其适用于特征的取值和输出的取值都是有限离散值的问题

#### 14.1决策树模型

输入进入到根节点,根据某个特征的取值,选择一个子节点进入,递归的进行根据特征选择子节点的操作,直到叶子节点.对于一个问题,可能有多个决策树,这些树有好有坏,我们的目标就是选择其中最好的树

#### 14.2决策树的学习过程

确定学习需要一下两个决定

一是选择哪一个特征进行抉择,目标是最大化纯度

二是何时停止分类:当分出的子类为一个纯类,或者当继续分类会超过最大深度时,或者分类使得纯度增长小于阈值,或者分类后的子类足够小

### 15纯度(熵)

为了进行上一节所说的两个决定,我们需要对纯度作出定义与操作

#### 15.1测量纯度

我们会用熵$H(p_1)$来表示纯度,$p_1$是我们想要测定的某一类在集合中的比例.针对二分问题,有公式$H(p_1) = -p_1\log_2(p_1) - p_0\log_2(p_0) = -p_1\log_2(p_1) - (1-p_1)\log_2(1-p_1)$.值越大,纯度越低.

#### 15.2拆分的选择:信息增益

我们将熵的减少称为信息增益.选择特征进行分类时,我们依据分类后每个自己的熵的加权平均数来决定,权由进入到该子集的用例数决定,将原来未分类的集合的熵减去这个加权平均数,得到的差称为信息增益.那么公式可以表示为:$InfomationGain = H(p_1^{root}) - (w^{left}H(p_1^{left}) - w^{right}H(p_1^{right})) $.

#### 15.3决策树构建的整体过程

* 以全部用例从根节点开始
* 对所有特征计算信息增益,选择最高的
* 根据特征区分集合,生成左右子树
* 对左右子树递归操作,直到:
  * 集合是一个纯集合
  * 继续分类会超过最大深度
  * 信息增益小于阈值
  * 集合中用例数量小于阈值

#### 15.4使用分类特征的一种独热编码

在上面我们讨论的都是二进制的特征,对于具有更多可能离散值的特征,需要独热编码来解决

对于多值,我们可以将多值转换为多个二进制的特征,这样,每一个特征总和到一起,形成了一个01的特征序列,这就是独热编码

#### 15.5连续有价值特征

在上一节我们考虑了多离散值的特征,那么进一步的,考虑连续值的特征.

对于连续的特征,我们就是利用一个阈值,来将连续的特征进行分为1或者0,对于具体的阈值,我们可以选择多个阈值,然后进行区分,计算信息增益,选择增益最大的阈值.事实证明这是有效的.

#### 15.6回归树

进一步的,我们将决策树推广到回归,由此可以预测任意可能的数字

首先对于如何选择特征进行分类,我们不在选择信息增益,而是利用子集内的方差,计算加权平均方差,然后将原来集合的方差减去这个加权平均,选择差最大的一个特征进行分类

而在最后输出时,只需输出对应的集合的平均值

### 16多个决策树

单个决策树可能对于数据过于敏感,为了增强鲁棒性,可以使用多个决策树,形成决策树集合.用例进入到集合中的每个树中,多者做为结果

#### 16.1放回抽样

从原有的训练用例中随机抽取用例,形成一个同样大小的新的训练集.这个训练集是决策森林中的重要的组件

#### 16.2随机森林算法

对于m大小的训练集,进行B次操作:每次进行返回抽样形成m大小的新训练集,利用这个新的训练集训练一颗树.这样共有B棵树,形成一个森林,结果为森林中的树的结果的投票多数.对于树的数量B,增加数量不会影响分类,但是过多时会影响速度.

进一步的进行改进,对于一棵树的节点,如果有n个特征,我们会从k<n的k个随机的特征中进行选择,一颗树中的节点只能从一个k大小的子集中选择.一般有$k=\sqrt{n}$.

#### 16.3XGBoost增强决策树

增强决策树的改变在于,算法中每次进行放回抽样时,不是随机的选择训练用例,而是倾向于选择上一棵树中错误的用例

XGBoost(eXtreme Gradient Boost)是一个常用的增强决策树算法.这个算法基于增强决策树,高效率,对于特征选择和分类停止的效果好,内部自带正则化,且对用例进行了加权.

#### 16.4何时使用决策树

决策树适用于:

* 结构化数据
* 需要速度快的

神经网络适用于:

* 所有类型的数据
* 不太在乎速度的
* 可预见性迁移学习的
* 多任务的

## 无监督学习、推荐系统、强化学习

无监督学习将主要包括聚类和异常检测,之后的两个内容时推荐系统和强化学习

### 1聚类

聚类是一种无监督学习,数据不需要标签,算法将在数据中寻找一种结构,来将数据进行处理

#### 1.1K-means聚类

K-meams算法做了两件事:所有的点分配到到最近的中心,中心更新位置.伪代码如下:

* 随机初始化K个簇中心$\mu_1,\mu_2,\ldots,\mu_k$,每个簇中心都是一个向量,向量维度与特征树、数一致
* 重复以下步骤:
  * for i = 1 to m:
    * $c^{(i)}$ = 距该数据最近的中心的标号
  * for k = 1 to K:
    * $\mu_k$ = 分配给该点的所有的点的平均位置,如果该中心没有被分配,则删除该点

#### 1.2优化目标

与之前的监督学习类似,K-means也是一种逐步降低代价的算法.令$\mu_{c^{(i)}}$是分配后的中心,则可以定义$J(c^{(1)},c^{(2)},\ldots c^{(m)},\mu_1,\mu_2,\ldots,\mu_k) = \frac{1}{m} \sum_{i=1}^m ||x^{(i)} - \mu_{c^{(i)}}||^2$.这个函数又称为失真函数.

#### 1.3初始化K-means算法

在算法开始时,我们随机取中心的位置.当然,K<m.所以一种随机确定的方法是从用例中随机抽取K个作为中心.不同的初始化可能导致不同的聚类结果,可以多次运行来选一个最好的.

#### 1.4聚类个数的选择

一种选择聚类个数的方法是肘法:J会随K的增加而增加,呈一个凹下降的趋势,可以取曲线弯曲时(肘部)时的K.进一步的,可以考虑我们分类的目的,来选择K

### 2异常检测

异常检测用于从数据集中挑出异常的数据.常用的方法是密度估计,我们检测数据集中特征的概率,如果用于测试的数据的预测值低于某个阈值,则标记异常,否则正常.

#### 2.1高斯分布(正态分布)

高斯分布时给定平均值和方差,由值可以得到概率.公式为:$p(x) = \frac{1}{\sqrt{2\pi} \sigma} e ^{\frac{-(x-\mu)^2}{2\sigma^2}}$.$\mu$影响曲线中心的位置,$\sigma$则影响曲线在某个位置的宽度.对于$\sigma$来讲,越大,曲线越平缓,越小,曲线越陡峭.

对于数据集,$\mu$为平均值,而$\sigma $为方差.进行操作时,给出输入,得到$p(x)$,如果值过低,则认为是异常的

#### 2.2异常检测算法

高斯分布只对一个特征进行计算,进一步,我们根据高斯分布得到算法

考虑一个$m$大小的数据集$\{x^{(1)},x^{(2)},\ldots x^{(n)}\}$,里面的每个用例$x_i$都有$n$个特征.那么对于输入进行检测的一个特征向量$x$有:$p(x) = \Pi_{j=1}^np(x_j;\mu_j,\sigma_j^2)$.然后如果$p(x)<\epsilon$则认为异常.

#### 2.3异常检测系统的建立与评估

实数评估是一种对异常检测系统的效果进行量化的方法,由这个方法可以计算对于参数的改变对于模型影响.

假设我们有一些进行过标签的数据,由此就可以建立训练集和CV集以及测试集.假定有10000个正常用例,20个异常用例,那么就可以:训练集:6000个正常用例;CV集:2000个正常用例和10个异常用例;测试集:2000个正常用例和10个异常用例.在CV集的效果上来改变参数.例外还有一种是不要测试集,剩下的加入到CV集中.

所以实数评估将模型在训练集上进行训练,然后在CV集上预测和评估.

#### 2.4异常检测与监督学习的比较

异常检测适用于:

* 异常数据过于少
* 有许多种异常,未来的异常可能与当前看到的异常不一样

监督学习适用于:

* 每种数据都有大量
* 异常数据有显著特征,未来的数据也与之前的数据类似

#### 2.5选择要使用的特征

考虑到异常检测的特殊情况,对于特征的选择尤其重要.

我们希望特征是高斯分布的,如太符合高斯分布,则需要对特征进行一些转换,变成具有高斯分布的.

最常见的问题是我们的模型会把一个异常的用例给一个较高的值,这时,我们进行误差分析,观察并改善这一情况

### 3推荐系统

考虑一个推荐系统,有用户$n_u$个,供推荐的产品$n_m$个,产品的特征有$n$个,那么对于第$j$个用户,第$i$个产品的评分可以为$w^{(j)} \cdot x^{(i)} + b^{(j)}$

#### 3.1使用每一项特征

上面的式子中,$w^{(i)},b^{(i)}$就是对于第$i$个用户的模型.我们再作出如下定义:

* $r(i,j)$表示用户$i$是否对产品$j$进行评分
* $y^{(i,j)}$代表用户$i$对产品$j$的评分
* $m^{(j)}$代表用户$j$进行评分的产品的数量

考虑到$m^{(j)}$是一个参数,那么对于用户$j$有代价函数为:$J(w^{(j)},b^{(j)}) = \frac{1}{2} \sum_{i:r(i,j)=1}(w^{(j)} \cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2}\sum_{k=1}^n(w_k^{(j)})^2$.接着,对于所有用户有:$J(w^{(1)},w^{(2)},\ldots w^{(n_u)},b^{(1)},b^{(2)},\ldots b^{(n_u)},) = \frac{1}{2}\sum_{j=1}^{n_u}( \sum_{i:r(i,j)=1}(w^{(j)} \cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + {\lambda}\sum_{k=1}^n(w_k^{(j)})^2)$.

#### 3.2协同过滤算法

进一步的,考虑我们无法获得产品的特征. 由此我们作出改进.

假定我们有若干用户的数据,那么反过来,我们可以估计出每个产品的特征.则同样可以在假定有用户数据的情况下,最小化所有产品特征的代价函数$J(x^{(1)},x^{(2)},\ldots x^{(n_m)}) = \frac{1}{2}\sum_{i=1}^{n_m}( \sum_{j:r(i,j)=1}(w^{(j)} \cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + {\lambda}\sum_{k=1}^n(x_k^{(i)})^2)$.如果我们将两个代价函数合起来,一起考虑就有:

$J(w^{(1)},w^{(2)},\ldots w^{(n_u)},b^{(1)},b^{(2)},\ldots b^{(n_u)},x^{(1)},x^{(2)},\ldots x^{(n_m)}) = \frac{1}{2} \sum_{(i,j):r(i,j)=1}(w^{(j)} \cdot x^{(i)} + b^{(j)} - y^{(i,j)})^2 + \frac{\lambda}{2}\sum _{j=1}^{n_u}\sum_{k=1}^n(w_k^{(j)})^2 + \frac{\lambda}{2}\sum_{i=1}^{n_m} \sum_{k=1}^n(x_k^{(i)})^2) $.

这样我们只需要评分就可以同时考虑用户和产品.之后我们只需对$w,b,x$都进行梯度下降即可.

#### 3.3二进制:喜欢或不喜欢

二进制可表现用户是否喜欢,是否点击,是否购买,是否浏览了足够长的时间.为了特化二进制功能,我们对代价函数进行修改,使其类似于逻辑回归:

$L(f_{(w,b,x)},y^{(i,j)}) = -y^{(i,j)}\log(f_{(w,b,x)}(x)) - (1-y^{(i,j)})\log(1-f_{(w,b,x)}(x) )$和

$J(w,b,x) = \sum_{(i,j):r(i,j)=1}L(f_{(w,b,x)},y^{(i,j)} )$.

由此即可实现.

#### 3.4均值归一化

对于推荐系统,进行类似与正则化的均值归一化也可以优化运行.

我们将所有的评分组成一个矩阵,然后对每个产品的评分去均值,形成一个向量,然后对于原来的矩阵,每个评分都要减去这个产品的均值形成新的矩阵.利用这个新的矩阵进行预测(当然,预测时要把减去的均值再加回来).

这个方法将对没有进行很多评分的用户进行预测时,变得更加有效

#### 3.5TensorFlow实现协同过滤

以下是一个简单的示例:

```python
optimizer = leras.optimizers.Adam(learning_rate=1e-1)
iteration = 200
for iter in range(iteration):
    with tf.GradientTape() as tape:
        cost_value = cofiCostFuncV(X, W, b, Ynorm, R, num_u, num_m, lambda)
        grads = tape.gradient(cost_value, [X,W,b])
        optimizer.apply_gradients(zip(grads, [X,W,b]))
```

#### 3.6查找相关内容

查找相关的产品,即是查找特征最相似的.

协同过滤存在以下缺点:

* 对于数据少的问题解决不利,也称为冷启动问题
* 相关信息的使用不好

### 4基于内容的过滤

协同过滤时基于评分,使用和目标评分接近的用户来推荐,而基于内容过滤基于用户和产品的特点来推荐.

我们使用$x_u^{(i)}$表示用户$i$的特征,用$x_m^{(j)}$表示产品$j$的特征.那么我们可以得到简化的用户$j$对产品$i$的预测:$w^{(j)}\cdot x^{(i)}$,我们换一种表示为:$v_u^{(j)}\cdot v_m^{(i)}$,其中的$v_u^{(j)}$是由用户$j$特征计算的向量,$v_m^{(i)}$是由产品$i$特征计算向量.利用两个$v$既可以表现特征,也可以统一大小从而点乘.

#### 4.1深度学习的基于内容的过滤

通过深度学习,我们可以将两个$x$变为两个$v$,从而进行预测并计算代价:$J = \sum_{(i,j):r(i,j)=1}(v_u^{(j)}\cdot v_m^{(i)} - y^{(i,j)})^2$

如果想进行相关推荐,可以计算$v$之间的距离来决定.

#### 4.2从大目录中推荐

实际中我们必须从巨型的数据集中进行选择,一般的大目录推荐由两步组成:检索和排名.

对于检索:系统找到用户最近的浏览,根据浏览找到近似的产品备选.接着利用模型,将备选的特征和用户的特征输入,根据预测评分进行排名来推荐

检索时可会遇到留下多少备选的问题,备选越多会越准确,但是更慢.可以进行实验来确定.

#### 4.3基于TensorFlow的基于内容的过滤

下面是一个简单的代码例子:

```python
user_NN = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(32)
])

item_NN = tf.keras.models.Sequential([
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(32)
])

input_user = tf.keras.layers.Input(shape=(num_user_features))
vu = user.NN(input_user)
vu = tf.linalg.l2_normalize(vu, axis=1)

input_item = tf.keras.layers.Input(shape=(num_item_features))
vm = user.NN(input_item)
vm = tf.linalg.l2_normalize(vm, axis=1)

output = tf.keras.layers.Dot(axes=1)([vu, vm])

model = Model([input_user, input_item], output)

cost_fn = tf.keras.losses.MeanSquaredError()
```

### 5强化学习

强化学习中的一个关键是奖励,用以提示AI如何做是好的.
